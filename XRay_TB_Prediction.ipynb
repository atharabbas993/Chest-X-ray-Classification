{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3tvrtvQlI95bU1DeIiWJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharabbas993/Chest-X-ray-Classification/blob/main/XRay_TB_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Kaggle API"
      ],
      "metadata": {
        "id": "ymL6PQHcYhXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vArVX4i5IcfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "7F7X-2-nYnb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tawsifurrahman/tuberculosis-tb-chest-xray-dataset"
      ],
      "metadata": {
        "id": "8g2sIUNHIzuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip Folder\n"
      ],
      "metadata": {
        "id": "PDyOYr8uY6-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/tuberculosis-tb-chest-xray-dataset.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()"
      ],
      "metadata": {
        "id": "oVcp-8jmJ0Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install split-folders"
      ],
      "metadata": {
        "id": "8G8d0j65JZwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Folder"
      ],
      "metadata": {
        "id": "vZ3LjJbFYtJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "#splits the data into 80% for training, 10% for validation, and 10% for testing.\n",
        "\n",
        "splitfolders.ratio(\"/content/TB_Chest_Radiography_Database\", output=\"output\", seed=1337, ratio=(.8, 0.1,0.1),group_prefix=None)\n"
      ],
      "metadata": {
        "id": "lrrkbYC0Jwtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Images\n"
      ],
      "metadata": {
        "id": "SsLMG7ceZK_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#Train data folder Directory\n",
        "\n",
        "train_dir = '/content/output/train'\n",
        "\n",
        "#Validation_Data_Directory\n",
        "\n",
        "validation_dir = '/content/output/val'\n",
        "\n",
        "#Test_Data_Directory\n",
        "\n",
        "test_dir = '/content/output/test'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Image Data Generator for augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "\n",
        "#____________Train_Data__________________\n",
        "\n",
        "# Load images from directories\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='binary'     # Binary classification\n",
        ")\n",
        "\n",
        "#___________Validation_Data__________________\n",
        "\n",
        "validation_data = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "#_____________Test_Data________________________\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "aGrFuJ6CKVH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build CNN"
      ],
      "metadata": {
        "id": "bY9C46CFKuST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#_________Convalutional_Layers_______\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#______Flatten_Layer___\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#______Fully_Connected_Layers______\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "1lHUlB-YKkS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Layers"
      ],
      "metadata": {
        "id": "-szN7DhxZQ7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "CQKvQcwBLNrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary\n"
      ],
      "metadata": {
        "id": "snSCrdifZXKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Shows the model's layer details and parameters.\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "k4hLF3AlLY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile Model"
      ],
      "metadata": {
        "id": "QZa5-EB-Ze4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LJrYplH0LdNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping"
      ],
      "metadata": {
        "id": "dezrNejCZjSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0,\n",
        ")"
      ],
      "metadata": {
        "id": "toIHYi0iLgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit Data to Model"
      ],
      "metadata": {
        "id": "C_S2arMqZnl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, epochs=30, validation_data=validation_data, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "UiqnragJLjN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Result Accuracy"
      ],
      "metadata": {
        "id": "JNdZlqJMZwzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FXm9hpHSLraT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Plot / Validation Plot\n"
      ],
      "metadata": {
        "id": "4HPHdVmxZ6Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#_____________Visualize_Training_Results_________________\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy and loss over epochs\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yivut4AXLzm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Loss / Validation Plot"
      ],
      "metadata": {
        "id": "IEiN1m-9aNnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot accuracy and loss\n",
        "def plot_training_history(history):\n",
        "    # Plot training and validation accuracy\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_training_history(history)\n"
      ],
      "metadata": {
        "id": "M3SamBvRL0Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Metrix"
      ],
      "metadata": {
        "id": "omtuCHSUaehI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Get true labels and predictions\n",
        "test_data.reset()  # Reset test data generator to prevent order mismatch\n",
        "y_true = test_data.classes\n",
        "y_pred = (model.predict(test_data) > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_data.class_indices.keys())\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=test_data.class_indices.keys()))\n"
      ],
      "metadata": {
        "id": "t4GPxiR9L5bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicted Probablity"
      ],
      "metadata": {
        "id": "MsHgT0SDajRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predicted probabilities\n",
        "y_probs = model.predict(test_data).flatten()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(y_probs, kde=True, bins=20, color='blue')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Predicted Probabilities')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LM-H07GEMBba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Scheduer\n"
      ],
      "metadata": {
        "id": "0hoIQL9tanry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you logged learning rates during training\n",
        "learning_rates = [0.001, 0.0009, 0.0008, 0.0007, 0.0006]  # Example values\n",
        "\n",
        "# Plot learning rate over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(learning_rates) + 1), learning_rates, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate Schedule')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X_DRGO3bMDjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Per Epochs"
      ],
      "metadata": {
        "id": "j08CYeHKa0U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "# If you tracked training time during each epoch:\n",
        "epoch_times = [5.2, 4.8, 5.1, 5.0, 5.3]  # Example times in seconds for each epoch\n",
        "\n",
        "# Plot training time per epoch\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, len(epoch_times) + 1), epoch_times, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.title('Training Time Per Epoch')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ktnb2sMEMHTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normal / Tuberclusis"
      ],
      "metadata": {
        "id": "jZHwetn8a-v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Count class instances\n",
        "class_counts = pd.DataFrame({\n",
        "    'Class': ['Normal', 'Tuberculosis'],\n",
        "    'Count': [len(os.listdir('/content/TB_Chest_Radiography_Database/Normal')), len(os.listdir('/content/TB_Chest_Radiography_Database/Tuberculosis'))]\n",
        "})\n",
        "\n",
        "# Bar plot of class distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='Class', y='Count', data=class_counts, palette='coolwarm')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DZvhWa60MJ5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Over Epoch"
      ],
      "metadata": {
        "id": "LY57KqORbIxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (Log Scale)')\n",
        "plt.title('Loss Over Epochs (Log Scale)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VD9rHi0QMMH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}